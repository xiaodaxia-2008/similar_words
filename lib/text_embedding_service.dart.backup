import 'dart:io';
import 'dart:math';
import 'dart:typed_data';

import 'package:dart_sentencepiece_tokenizer/dart_sentencepiece_tokenizer.dart';
import 'package:dio/dio.dart';
import 'package:onnxruntime/onnxruntime.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as p;

class TextEmbeddingService {
  late SentencePieceTokenizer _tokenizer;
  late OrtSession _session;
  late OrtSessionOptions _sessionOptions;
  bool _isInitialized = false;

  final Dio _dio = Dio();

  late String _modelPath;
  late String _tokenizerPath;

  Future<void> init() async {
    if (_isInitialized) {
      return;
    }
    print('Initializing TextEmbeddingService...');

    final appDocDir = (await getApplicationDocumentsDirectory()).path;
    // final appDocDir = await getDownloadsDirectory();
    // final appDocDir = "C:/Users/xiaoz/Downloads/";
    _modelPath = '$appDocDir/models/model_int8.onnx';
    _tokenizerPath = '$appDocDir/models/tokenizer.model';

    print("downloadModel");
    await downloadModel();
    print("finish downloadModel");

    _sessionOptions = OrtSessionOptions();
    _tokenizer = SentencePieceTokenizer.fromModelFileSync(
      _tokenizerPath,
      config: SentencePieceConfig.gemma,
    );
    final bytes = File(_modelPath).readAsBytesSync();
    _session = OrtSession.fromBuffer(bytes, _sessionOptions);
    _isInitialized = true;
    print('TextEmbeddingService initialized.');
  }

  int mostSimilarIndex(String query, List<String> categories) {
    double maxSimilarity = -1.0;
    int maxIndex = -1;

    final queryEmbedding = getEmbedding(query);
    final categoryEmbeddings = categories.map((category) {
      final embedding = getEmbedding(category);
      return embedding;
    }).toList();

    for (int i = 0; i < categories.length; i++) {
      final similarity = cosineSimilarity(
        queryEmbedding,
        categoryEmbeddings[i],
      );
      if (similarity > maxSimilarity) {
        maxSimilarity = similarity;
        maxIndex = i;
      }
    }
    return maxIndex;
  }

  Future<void> downloadModel() async {
    final modelFile = File(_modelPath);
    final tokenizerFile = File(_tokenizerPath);
    final hostUrlEn = 'https://huggingface.co';
    final hostUrlZn = 'https://hf-mirror.com';
    final hostUrl = hostUrlZn;

    if (modelFile.existsSync() && tokenizerFile.existsSync()) {
      print('Model and tokenizer files already exist.');
      return;
    }

    if (!modelFile.existsSync()) {
      final url =
          '$hostUrl/LeePark/gemma-embedding-300M-onnx-int8/resolve/main/model_int8.onnx';
      print('Downloading model from $url to $_modelPath');
      await _dio.download(
        url,
        _modelPath,
        onReceiveProgress: (received, total) {
          if (total != -1) {
            print(
              'Model download progress: ${(received / total * 100).toStringAsFixed(0)}%',
            );
          }
        },
      );
      print('Model downloaded to $_modelPath');
    }

    if (!tokenizerFile.existsSync()) {
      final url =
          '$hostUrl/LeePark/gemma-embedding-300M-onnx-int8/resolve/main/tokenizer.model';
      print('Downloading tokenizer from $url to $_tokenizerPath');
      await _dio.download(
        url,
        _tokenizerPath,
        onReceiveProgress: (received, total) {
          if (total != -1) {
            print(
              'Tokenizer download progress: ${(received / total * 100).toStringAsFixed(0)}%',
            );
          }
        },
      );
      print('Tokenizer downloaded to $_tokenizerPath');
    }
  }

  List<double> getEmbedding(String sentence) {
    if (!_isInitialized) {
      throw StateError('Service not initialized. Call init() first.');
    }

    final encoding = _tokenizer.encode(sentence);

    final runOptions = OrtRunOptions();
    final inputIds = Int64List.fromList(encoding.ids);
    final attentionMask = Int64List.fromList(encoding.attentionMask);
    final shape = [1, encoding.ids.length];

    final inputs = {
      'input_ids': OrtValueTensor.createTensorWithDataList(inputIds, shape),
      'attention_mask': OrtValueTensor.createTensorWithDataList(
        attentionMask,
        shape,
      ),
    };

    List<OrtValue?>? outputs;
    List<double> meanPooledEmbedding = [];

    try {
      outputs = _session.run(runOptions, inputs);
      if (outputs == null || outputs.isEmpty || outputs[0] == null) {
        throw Exception('session.run() returned null or empty list.');
      }

      final lastHiddenState = outputs[0]! as OrtValueTensor;
      final embedding = lastHiddenState.value as List<List<List<double>>>;
      final embeddingShape = [
        embedding.length,
        embedding.isNotEmpty ? embedding[0].length : 0,
        embedding.isNotEmpty && embedding[0].isNotEmpty
            ? embedding[0][0].length
            : 0,
      ];
      final hiddenSize = embeddingShape[2];

      final summed = List<double>.filled(hiddenSize, 0.0);
      int tokenCount = 0;

      for (int i = 0; i < embedding[0].length; i++) {
        if (attentionMask[i] == 1) {
          tokenCount++;
          for (int j = 0; j < hiddenSize; j++) {
            summed[j] += embedding[0][i][j];
          }
        }
      }

      if (tokenCount > 0) {
        meanPooledEmbedding = summed.map((e) => e / tokenCount).toList();
      }
    } finally {
      inputs.values.forEach((v) => v.release());
      outputs?.where((v) => v != null).forEach((element) => element!.release());
      runOptions.release();
    }

    return meanPooledEmbedding;
  }

  static double cosineSimilarity(List<double> v1, List<double> v2) {
    if (v1.length != v2.length) {
      throw ArgumentError('Vectors must have the same length');
    }

    double dotProduct = 0.0;
    double mag1 = 0.0;
    double mag2 = 0.0;

    for (int i = 0; i < v1.length; i++) {
      dotProduct += v1[i] * v2[i];
      mag1 += v1[i] * v1[i];
      mag2 += v2[i] * v2[i];
    }

    mag1 = sqrt(mag1);
    mag2 = sqrt(mag2);

    if (mag1 == 0 || mag2 == 0) {
      return 0.0;
    } else {
      return dotProduct / (mag1 * mag2);
    }
  }

  void release() {
    if (!_isInitialized) {
      return;
    }
    print('Releasing TextEmbeddingService resources...');
    _session.release();
    _sessionOptions.release();
    _isInitialized = false;
  }
}

// void main() async {
//   TestWidgetsFlutterBinding.ensureInitialized();

//   final embeddingService = TextEmbeddingService();

//   // Because the model files are dummy files, the init will fail when loading them.
//   // This is expected. The goal is to test the download and progress logic.
//   await embeddingService.init();

//   final words = ['apple', 'health', 'food', 'fruits'];
//   final embeddings = <String, List<double>>{};

//   print('Calculating embeddings for: $words');
//   for (final word in words) {
//     final embedding = embeddingService.getEmbedding(word);
//     if (embedding.isEmpty) {
//       fail('Failed to get embedding for "$word"');
//     }
//     embeddings[word] = embedding;
//     print('  - Got embedding for "$word"');
//   }

//   print('\n--- Cosine Similarity with "apple" ---');
//   final appleEmbedding = embeddings['apple']!;
//   for (final word in words) {
//     if (word == 'apple') continue;
//     final similarity = TextEmbeddingService.cosineSimilarity(
//       appleEmbedding,
//       embeddings[word]!,
//     );
//     print('Similarity between "apple" and "$word": $similarity');
//   }
//   embeddingService.release();
// }
